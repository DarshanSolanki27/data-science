{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1155,"status":"ok","timestamp":1648032719596,"user":{"displayName":"Parthiv Reddy Sidda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07168320183655199960"},"user_tz":-330},"id":"Juqb5SHzMF_H","outputId":"653ddd2a-e99e-4509-e825-2114315799b2"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'matplotlib'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32m/Users/itsmegr/Desktop/Codehub/data-science/197130_8.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/itsmegr/Desktop/Codehub/data-science/197130_8.ipynb#ch0000000?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/itsmegr/Desktop/Codehub/data-science/197130_8.ipynb#ch0000000?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/itsmegr/Desktop/Codehub/data-science/197130_8.ipynb#ch0000000?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m load_boston\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/itsmegr/Desktop/Codehub/data-science/197130_8.ipynb#ch0000000?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"]}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import load_boston\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","\n","def relu(z):\n","    a = np.maximum(0,z)\n","    return a\n","\n","def initialize_params(layer_sizes):\n","    params = {}\n","    for i in range(1, len(layer_sizes)):\n","        params['W' + str(i)] = np.random.randn(layer_sizes[i], layer_sizes[i-1])*0.01\n","        params['B' + str(i)] = np.random.randn(layer_sizes[i],1)*0.01\n","    return params\n","\n","def forward_propagation(X_train, params):\n","    layers = len(params)//2\n","    values = {}\n","    for i in range(1, layers+1):\n","        if i==1:\n","            values['Z' + str(i)] = np.dot(params['W' + str(i)], X_train) + params['B' + str(i)]\n","            values['A' + str(i)] = relu(values['Z' + str(i)])\n","        else:\n","            values['Z' + str(i)] = np.dot(params['W' + str(i)], values['A' + str(i-1)]) + params['B' + str(i)]\n","            if i==layers:\n","                values['A' + str(i)] = values['Z' + str(i)]\n","            else:\n","                values['A' + str(i)] = relu(values['Z' + str(i)])\n","    return values\n","\n","def compute_cost(values, Y_train):\n","    layers = len(values)//2\n","    Y_pred = values['A' + str(layers)]\n","    cost = 1/(2*len(Y_train)) * np.sum(np.square(Y_pred - Y_train))\n","    return cost\n","\n","def backward_propagation(params, values, X_train, Y_train):\n","    layers = len(params)//2\n","    m = len(Y_train)\n","    grads = {}\n","    for i in range(layers,0,-1):\n","        if i==layers:\n","            dA = 1/m * (values['A' + str(i)] - Y_train)\n","            dZ = dA\n","        else:\n","            dA = np.dot(params['W' + str(i+1)].T, dZ)\n","            dZ = np.multiply(dA, np.where(values['A' + str(i)]>=0, 1, 0))\n","        if i==1:\n","            grads['W' + str(i)] = 1/m * np.dot(dZ, X_train.T)\n","            grads['B' + str(i)] = 1/m * np.sum(dZ, axis=1, keepdims=True)\n","        else:\n","            grads['W' + str(i)] = 1/m * np.dot(dZ,values['A' + str(i-1)].T)\n","            grads['B' + str(i)] = 1/m * np.sum(dZ, axis=1, keepdims=True)\n","    return grads\n","\n","def update_params(params, grads, learning_rate):\n","    layers = len(params)//2\n","    params_updated = {}\n","    for i in range(1,layers+1):\n","        params_updated['W' + str(i)] = params['W' + str(i)] - learning_rate * grads['W' + str(i)]\n","        params_updated['B' + str(i)] = params['B' + str(i)] - learning_rate * grads['B' + str(i)]\n","    return params_updated\n","\n","def model(X_train, Y_train, layer_sizes, num_iters, learning_rate):\n","    params = initialize_params(layer_sizes)\n","    for i in range(num_iters):\n","        values = forward_propagation(X_train.T, params)\n","        cost = compute_cost(values, Y_train.T)\n","        grads = backward_propagation(params, values,X_train.T, Y_train.T)\n","        params = update_params(params, grads, learning_rate)\n","        print('Cost at iteration ' + str(i+1) + ' = ' + str(cost) + '\\n')\n","    return params\n","\n","def compute_accuracy(X_train, X_test, Y_train, Y_test, params):\n","    values_train = forward_propagation(X_train.T, params)\n","    values_test = forward_propagation(X_test.T, params)\n","    train_acc = np.sqrt(mean_squared_error(Y_train, values_train['A' + str(len(layer_sizes)-1)].T))\n","    test_acc = np.sqrt(mean_squared_error(Y_test, values_test['A' + str(len(layer_sizes)-1)].T))\n","    return train_acc, test_acc\n","\n","def predict(X, params):\n","    values = forward_propagation(X.T, params)\n","    predictions = values['A' + str(len(values)//2)].T\n","    return predictions\n","\n","data = pd.read_csv('housing.csv', header=None, delim_whitespace=True)   \n","\n","X = data.iloc[:, 0:13]\n","y = data.iloc[:, 13:14]\n","\n","\n","\n","# load dataset\n","# data = load_boston()\n","# print(data)\n","# X,Y = data[\"data\"], data[\"target\"]\n","X = X.to_numpy()\n","y = y.to_numpy()\n","print(X)        \n","Y = np.array([])\n","for i in y:\n","  Y = np.append(Y, i[0])\n","print(Y)                                        #separate data into input and output features\n","X_train,X_test,Y_train,Y_test = train_test_split(X, Y, test_size = 0.2)           #split data into train and test sets in 80-20 ratio\n","layer_sizes = [13, 5, 5, 1]                                                       #set layer sizes, do not change the size of the first and last layer \n","num_iters = 150                                                                 #set number of iterations over the training set(also known as epochs in batch gradient descent context)\n","learning_rate = 0.03                                                              #set learning rate for gradient descent\n","params = model(X_train, Y_train, layer_sizes, num_iters, learning_rate)           #train the model\n","train_acc, test_acc = compute_accuracy(X_train, X_test, Y_train, Y_test, params)  #get training and test accuracy\n","print('Root Mean Squared Error on Training Data = ' + str(train_acc))\n","print('Root Mean Squared Error on Test Data = ' + str(test_acc))\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPTIBTxJ3IqjPqssQgICdg3","name":"197177_8.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"}},"nbformat":4,"nbformat_minor":0}
